# Pattern Registry (Internal)

Record coding/architectural patterns used in CSV Detox.
Update only after asking and receiving approval for new patterns/libraries.

## Current patterns

### Folder conventions
- `src/lib/**` contains pure logic (parsers, validators, utilities, business logic)
- `src/app/**` contains Next.js App Router pages and layouts
- `src/components/ui/**` contains shadcn/ui components (auto-generated, customizable)
- `src/components/**` contains application-specific React components
- `convex/**` contains Convex backend code (schema, mutations, queries)

### Backend: Convex + Postgres
- **Convex** is used as the backend-as-a-service platform
- **Convex file storage** stores uploaded files (CSV/XLSX)
- **Database**: Convex's built-in document database stores metadata
- **Postgres integration**: Available via Convex dashboard for future relational features
- File IDs are generated by the Convex database (not client-side UUIDs)

### File Upload Pattern
- Client calls `generateUploadUrl` mutation to get upload URL
- Client uploads file directly to Convex storage
- Client calls `uploadFile` mutation with storage ID + metadata
- Mutation validates file and stores metadata in database
- All validation logic lives in Convex mutations (server-side)

### React Integration
- `ConvexProvider` wraps the app in `layout.tsx`
- Pages use `useMutation` and `useQuery` hooks from `convex/react`
- All Convex functions are strongly typed via generated API (`convex/_generated/api`)

### UI Components: shadcn/ui
- **Component library**: shadcn/ui (Tailwind CSS-based, copy-paste components)
- **Installation**: `npx shadcn@latest add <component>` - components are copied to `src/components/ui/`
- **Customization**: Edit components in `src/components/ui/` after installation as needed
- **Styling**: Uses Tailwind CSS utility classes
- **Philosophy**: Components are owned by the project (not npm dependencies), allowing full customization
- **Common components**:
  - `button` - Buttons with variants (default, destructive, outline, ghost, link)
  - `card` - Cards with header, content, footer
  - `table` - Data tables with sorting, filtering
  - `dialog` - Modal dialogs
  - `select` - Dropdown selects
  - `input` - Form inputs
- **Pattern**: Use shadcn/ui as the base, compose application-specific components in `src/components/`
- **Documentation**: https://ui.shadcn.com/docs

### Testing Patterns
- **Framework**: Node.js built-in test runner with tsx for TypeScript support
- **Test location**: `__tests__` directories next to the code being tested
- **Test naming**: `*.test.ts` files
- **Unit tests**: Pure functions in `src/lib/**` are unit tested in isolation
- **Integration tests**: Convex mutations tested using Convex test helpers (future)
- **Run tests**: `npm test` - runs all tests, exits with code 0 on success
- **Watch mode**: `npm run test:watch` - reruns tests on file changes
- **Coverage**: All validation logic must have >90% test coverage
- **Test structure**: Use `describe` for grouping, `it` for individual tests
- **Assertions**: Use Node's built-in `assert` module

### DuckDB-WASM Export Patterns

**Overview**: Client-side full-file export using DuckDB-WASM to overcome Convex's 64MB memory limit.

**When to Use**:
- Export functionality that needs to process files larger than 5000 rows
- Preview stays server-side (fast, 5000-row limit)
- Export uses DuckDB-WASM (unlimited rows, browser-side)

**Key Files**:
- `src/lib/duckdb/exporter.ts` - Main orchestration
- `src/lib/duckdb/sql-translator.ts` - Pipeline → SQL conversion
- `src/lib/duckdb/init.ts` - DuckDB-WASM initialization with caching
- `src/lib/duckdb/loader.ts` - File loading into DuckDB

**SQL Translation Pattern**:
All transformation operations translate to DuckDB SQL:

```typescript
// Example: Trim operation
const steps: TransformationStep[] = [
  { id: "1", type: "trim", config: { type: "trim", columns: ["name"] } }
];

const sql = translatePipeline(steps);
// Returns: ['UPDATE data SET "name" = TRIM("name")']
```

**Important SQL rules**:
- Identifiers (columns): Double quotes `"column_name"`
- String literals: Single quotes `'value'`
- Escape by doubling: `"col""name"` for identifiers, `'val''ue'` for literals
- Table name is always `data`
- Use ROWID for ordering (DuckDB built-in)

**Progress Tracking Pattern**:
```typescript
await exportWithDuckDB({
  uploadId,
  fileUrl,
  mimeType,
  fileName,
  steps,
  parseConfig,
  onProgress: (progress) => {
    // progress.stage: 'initializing' | 'downloading' | 'loading' | 'transforming' | 'generating' | 'ready' | 'error'
    // progress.message: Human-readable status
    // progress.bytesDownloaded, totalBytes (for downloading stage)
    // progress.currentStep, totalSteps (for transforming stage)
  },
});
```

**Memory Optimization**:
- DuckDB instance cached globally (instant subsequent exports)
- In-place UPDATEs instead of creating new tables
- File streaming during download
- Memory cleanup on errors

**Error Handling**:
```typescript
try {
  const result = await exportWithDuckDB(options);
} catch (error) {
  if (error instanceof BrowserOOMError) {
    // Show "Try exporting smaller file" message
  } else if (error instanceof DuckDBExecutionError) {
    // SQL execution failed, show error.sql and error.message
  } else if (error instanceof SQLTranslationError) {
    // Pipeline → SQL translation failed
  }
}
```

**Testing Pattern**:
SQL translator tests use pure TypeScript (no DuckDB required):

```typescript
it("should generate UPDATE statement for trim", () => {
  const steps: TransformationStep[] = [
    { id: "1", type: "trim", config: { type: "trim", columns: ["name"] } }
  ];
  const sql = translatePipeline(steps);
  assert.strictEqual(sql[0], 'UPDATE data SET "name" = TRIM("name")');
});
```

**Browser Compatibility**:
- Chrome, Firefox, Safari, Edge: Full support
- Mobile: Limited to ~50MB files
- Requires Web Worker support
- WASM memory limit: 4GB

### Planned
- Authorization approach (to be documented when introduced)
